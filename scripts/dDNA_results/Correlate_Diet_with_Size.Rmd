---
title: "Diet by Size"
subtitle: "run date: `r format(Sys.time(), '%B %d, %Y')`"
author: "M Fisher"
date: 'written 2022-9-19'
output: 
  html_document:
    toc: yes
    toc_float: yes
---

# Description

Is diet variability correlated with instar size?

https://rachaellappan.github.io/16S-analysis/correlation-between-otus-with-sparcc.html
https://biovcnet.github.io/_pages/NetworkScience_SparCC.nb.html

or, Djurhuus et al. paper with weighted correlation network analysis https://www.nature.com/articles/s41467-019-14105-1#code-availability

In order to directly associate specific taxa to environmental variables (Fig. 3), we used sparse partial least square (sPLS) analysis from the R package mixOmics57,58. We applied the sPLS in regression mode, which will model a causal relationship between the lineages and the environmental traits, that is, PLS will predict environmental traits (e.g., temperature) from lineage abundances. This approach enabled us to identify strong correlations between certain taxa and environmental variables without taking into account the global structure of the planktonic community.



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(here)
library(ggplot2)
library(ggrepel)
library(cowplot)
library(vegan)
library(sandwich)
library(MASS)
library(lmtest)
library(labdsv)
library(magrittr)
# library(devtools)
# devtools::install_github("mixOmicsTeam/mixOmics")
library(mixOmics)
library(zoid)
library(CCA)
library(arm)

# remotes::install_github("gavinsimpson/ggvegan")
library(ggvegan)

source(here('R','eDNA_index.r'))

# User inputs
blastdir   <- 'data/blast'
resultsdir <- 'data/results'
run.nums <- c(1,2)
marker  <- 'lerayXT'

site_names <- data.frame(site=c("KAY","KAY-shell","MARPT","PBNERR","SAMI","SAMT","LAR"),
                         site_name=c("Kayak Pt 1","Kayak Pt 2","March Pt",
                                   "NERR","Samish Isl","Samish Bay","Larrabee"))

knitting=TRUE
```

```{r data, include=FALSE}
## lab metadata (CH,CW,fullness) ##
lab_metadat <- read_csv(here('data','metadata','crab_metadat.csv'))

## filtered taxa ##
dat <- read_csv(here(blastdir, paste0(marker,"_","r",paste(run.nums,collapse="-"),"_sample_taxonomy_filtered2_uniqueTaxa.csv")))

dat %<>%
  mutate(site=ifelse(site=="KAY" & crab_num > 18, "KAY-shell",site)) %>%
  mutate(site=ifelse(site=="CLAY","LAR",
                     ifelse(site=="SIN","SAMI",site))) %>%
  mutate(estuary=ifelse(site %in% c("KAY","KAY-shell"),"Port Susan Bay",
                                    ifelse(site %in% c("LAR","SAMT","SAMI"), "Samish Bay","Padilla Bay")))

## too small taxa (aka "detritus") ##
smdat <- read_csv(here(blastdir, paste0(marker,"_","r",paste(run.nums,collapse="-"),"_sample_taxonomy_SmallTaxa_uniqueTaxa.csv")))  

smdat %<>%
  mutate(site=ifelse(site=="KAY" & crab_num > 18, "KAY-shell",site)) %>%
  mutate(site=ifelse(site=="CLAY","LAR",
                     ifelse(site=="SIN","SAMI",site))) %>%
  mutate(estuary=ifelse(site %in% c("KAY","KAY-shell"),"Port Susan Bay",
                                    ifelse(site %in% c("LAR","SAMT","SAMI"), "Samish Bay","Padilla Bay")))
```


## Prep size data

First, create a data frame with only the carapace width data, per technical replicate. 
```{r}
cw.techs.df <- lab_metadat %>% dplyr::select(sample_id,CW_mm) %>%
  rename(crab_id=sample_id) %>%
  left_join(bind_rows(dat,smdat) %>% dplyr::select(crab_id,sample_id,tech) %>% distinct,
            by=c("crab_id")) %>%
  filter(!is.na(tech))
```


Do the same, but only once per crab
```{r}
cw.df <- lab_metadat %>% dplyr::select(sample_id,CW_mm) %>%
  rename(crab_id=sample_id) %>%
  left_join(bind_rows(dat,smdat) %>% dplyr::select(crab_id) %>% distinct() %>% mutate(presence=1),
            by=c("crab_id")) %>%
  filter(!is.na(presence)) %>% dplyr::select(-presence)


if(!knitting){
  saveRDS(cw.df, here('data','metadata','carapace_widths_for_zoid.rds'))
}
```


Then, calculate the eDNA index. I did this in two ways: first, for each technical replicate from the raw sequence abudance data, and then, for each crab. To collapse the replicates per crab, I summed reads across replicates and then divided by the number of replicates. 

**all taxa**: each replicate
```{r}
crab.reads.mat <- bind_rows(smdat,
                            dat %>% dplyr::select(-taxon) %>% rename(taxon=new_taxon)) %>%
  group_by(sample_id, taxon) %>% summarise(techReads=sum(nReads)) %>%
  pivot_wider(id_cols="sample_id", names_from="taxon",values_from="techReads", values_fill=0) %>%
  column_to_rownames("sample_id")

index.mat <- t(eDNA_index(x=t(crab.reads.mat)))

index.df <- as.data.frame(index.mat) %>%
  rownames_to_column("sample_id") %>% 
  pivot_longer(cols=2:(dim(index.mat)[2]+1), names_to="taxon",values_to="DNAindex") %>%
  left_join(dat %>% dplyr::select(sample_id,crab_id,tech,site,estuary) %>% distinct(),by="sample_id") %>%
  left_join(site_names) %>%
  pivot_wider(names_from=taxon,values_from=DNAindex)
```

check to make sure all technical replicates are in both data frames
```{r}
all(rownames(index.mat) %in% cw.techs.df$sample_id)
```

**all taxa**: each crab
```{r}
crabID.reads.mat <- bind_rows(smdat,
                            dat %>% dplyr::select(-taxon) %>% rename(taxon=new_taxon)) %>%
  group_by(crab_id, taxon) %>% summarise(crabReads=sum(nReads),ntechs=length(unique(sample_id))) %>%
  mutate(crabReads_std=crabReads/ntechs) %>% 
  dplyr::select(-crabReads,ntechs) %>%
  pivot_wider(id_cols="crab_id", names_from="taxon",values_from="crabReads_std", values_fill=0) %>%
  column_to_rownames("crab_id")

index.mat2 <- t(eDNA_index(x=t(crabID.reads.mat)))

index.df2 <- as.data.frame(index.mat2) %>%
  rownames_to_column("crab_id") %>% 
  pivot_longer(cols=2:(dim(index.mat2)[2]+1), names_to="taxon",values_to="DNAindex") %>%
  left_join(bind_rows(
    dat %>% dplyr::select(crab_id,site,estuary) %>% distinct(),
    smdat %>% dplyr::select(crab_id,site,estuary) %>% distinct()) %>% distinct(),
    ,by="crab_id") %>%
  left_join(site_names) %>%
  pivot_wider(names_from=taxon,values_from=DNAindex)
```



**large taxa only**: each replicate
```{r}
crab.lreads.mat <- dat %>%
  group_by(sample_id, new_taxon) %>% summarise(techReads=sum(nReads)) %>%
  pivot_wider(id_cols="sample_id", names_from="new_taxon",values_from="techReads", values_fill=0) %>%
  column_to_rownames("sample_id")

index.lg.mat <- t(eDNA_index(x=t(crab.lreads.mat)))

index.lg.df <- as.data.frame(t(index.lg.mat)) %>%
  rownames_to_column("sample_id") %>% 
  pivot_longer(cols=2:(dim(index.lg.mat)[1]+1), names_to="taxon",values_to="DNAindex") %>%
  left_join(dat %>% dplyr::select(sample_id,crab_id,tech,site,estuary) %>% distinct(),by="sample_id") %>%
  left_join(site_names) %>%
  pivot_wider(names_from=taxon,values_from=DNAindex)
```

**large taxa only**: each crab
```{r}
# matrix with samples in rows, taxa in columns
crabID.lreads.mat <- dat %>%
  group_by(crab_id, new_taxon) %>% summarise(crabReads=sum(nReads),ntechs=length(unique(sample_id))) %>%
  mutate(crabReads_std=crabReads/ntechs) %>% 
  dplyr::select(-crabReads,ntechs) %>%
  pivot_wider(id_cols="crab_id", names_from="new_taxon",values_from="crabReads_std", values_fill=0) %>%
  column_to_rownames("crab_id")

index.lg.mat2 <- t(eDNA_index(x=t(crabID.lreads.mat)))  # need to transpose above matrix

index.lg.df2 <- as.data.frame(index.lg.mat2) %>%
  rownames_to_column("crab_id") %>% 
  pivot_longer(cols=2:(dim(index.lg.mat2)[2]+1), names_to="taxon",values_to="DNAindex") %>%
  left_join(dat %>% dplyr::select(crab_id,site,estuary) %>% distinct(),by="crab_id") %>%
  left_join(site_names) %>%
  pivot_wider(names_from=taxon,values_from=DNAindex)
```



**micro taxa only**: each replicate
```{r}
crab.smreads.mat <- smdat %>%
  group_by(sample_id, taxon) %>% summarise(techReads=sum(nReads)) %>%
  pivot_wider(id_cols="sample_id", names_from="taxon",values_from="techReads", values_fill=0) %>%
  column_to_rownames("sample_id")

index.sm.mat <- t(eDNA_index(x=t(crab.smreads.mat)))
```
**micro taxa only**: each crab
```{r}
crabID.smreads.mat <- smdat %>%
  group_by(crab_id, taxon) %>% summarise(crabReads=sum(nReads),ntechs=length(unique(sample_id))) %>%
  mutate(crabReads_std=crabReads/ntechs) %>% 
  dplyr::select(-crabReads,ntechs) %>%
  pivot_wider(id_cols="crab_id", names_from="taxon",values_from="crabReads_std", values_fill=0) %>%
  column_to_rownames("crab_id")

index.sm.mat2 <- t(eDNA_index(x=t(crabID.smreads.mat)))

index.sm.df2 <- as.data.frame(index.sm.mat2) %>%
  rownames_to_column("crab_id") %>%
  pivot_longer(cols=2:(dim(index.sm.mat2)[2]+1), names_to="taxon",values_to="DNAindex") %>%
  left_join(smdat %>% dplyr::select(crab_id,site,estuary) %>% distinct(),by="crab_id") %>%
  left_join(site_names) %>%
  pivot_wider(names_from=taxon,values_from=DNAindex)
```




### student's t-test

Does carapace width vary significantly between estuaries?
```{r}
cw.est.df <- cw.df %>%
  left_join(dplyr::select(lab_metadat, sample_id,estuary), by=c("crab_id"="sample_id"))

t.test(x=filter(cw.est.df, estuary=="Padilla Bay")$CW_mm, y=filter(cw.est.df, estuary=="Port Susan Bay")$CW_mm)
t.test(x=filter(cw.est.df, estuary=="Padilla Bay")$CW_mm, y=filter(cw.est.df, estuary=="Samish Bay")$CW_mm)
t.test(x=filter(cw.est.df, estuary=="Port Susan Bay")$CW_mm, y=filter(cw.est.df, estuary=="Samish Bay")$CW_mm)
```

```
Welch Two Sample t-test

data:  filter(cw.est.df, estuary == "Padilla Bay")$CW_mm and filter(cw.est.df, estuary == "Port Susan Bay")$CW_mm
t = 2.2191, df = 14.633, p-value = 0.04274
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 0.08005857 4.20024446
sample estimates:
mean of x mean of y 
10.708333  8.568182 


	Welch Two Sample t-test

data:  filter(cw.est.df, estuary == "Padilla Bay")$CW_mm and filter(cw.est.df, estuary == "Samish Bay")$CW_mm
t = 1.6536, df = 17.828, p-value = 0.1157
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -0.4580056  3.8330056
sample estimates:
mean of x mean of y 
10.708333  9.020833 


	Welch Two Sample t-test

data:  filter(cw.est.df, estuary == "Port Susan Bay")$CW_mm and filter(cw.est.df, estuary == "Samish Bay")$CW_mm
t = -0.74458, df = 41.291, p-value = 0.4607
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -1.6801266  0.7748236
sample estimates:
mean of x mean of y 
 8.568182  9.020833 
```

Multiply by three for Bonferroni correction:
```{r}
p  <-  0.04274; p*3
```


## Zoid: common taxa

Since we're only interested in the extent to which the prevalence of each taxon is upweighted / downweighted when size increases, it's ok to use the proportion of total sequences as zoid input. 

Then the covariate will be carapace width.

As with the green crab diet data, the general sparsity of the data is still a problem for zoid. So the option is to either filter species or aggregate them into groups. 


### common taxa (filter)

Remove taxa that occur in fewer than ten crab (not super useful for comparing across sizes). the function `dropspc` assumes that the species are in columns of the matrix. Otherwise, **zoid will not run**
```{r}
crabID.reads.filter.mat <- dropspc(crabID.reads.mat, minocc=9)
crabID.reads.filter.mat <- crabID.reads.filter.mat[which(rowSums(crabID.reads.filter.mat) > 0),]

dim(crabID.reads.mat); dim(crabID.reads.filter.mat)
```

Get the proportion of each crab's total reads that belong to each species
```{r}
crabID.preads.mat <- decostand(x=crabID.reads.filter.mat,method="total",MARGIN=1)
```

join with carapace widths
```{r}
# zoidIN.std.reads <- std.reads.mat %>%
#   left_join(cw.df,by=c("crab"="crab_id")) %>%
#   column_to_rownames("crab")

zoidIN.std.reads <- crabID.preads.mat %>%
  rownames_to_column("crab") %>%
  left_join(cw.df,by=c("crab"="crab_id")) %>%
  column_to_rownames("crab")

any(is.na(zoidIN.std.reads$CW_mm))
```

#### run zoid
create the design matrix (site / site type information per observation, aka per crab) and the data matrix (read counts only)
```{r}
design_matrix = zoidIN.std.reads[,which(names(zoidIN.std.reads)=="CW_mm"), drop=FALSE]
data_matrix = zoidIN.std.reads[,which(names(zoidIN.std.reads)!="CW_mm")]
design_matrix$y = 1 # dummy variable
```

attempt to zoid!
```{r eval=FALSE}
fit_2_prey <- fit_zoid(formula = y ~ CW_mm, 
                       design_matrix = design_matrix, 
                       data_matrix = as.matrix(data_matrix),
                       overdispersion = TRUE,
                       chains=4,
                       iter=5000,
                       overdispersion_sd = 0.1)
```
```
SAMPLING FOR MODEL 'dirichregmod' NOW (CHAIN 1).
Chain 1: Rejecting initial value:
Chain 1:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 1:   Stan can't start sampling from this initial value.
Chain 1: Rejecting initial value:
Chain 1:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 1:   Stan can't start sampling from this initial value.
Chain 1: Rejecting initial value:
Chain 1:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 1:   Stan can't start sampling from this initial value.
Chain 1: 
Chain 1: Gradient evaluation took 0.002 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 20 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 5000 [  0%]  (Warmup)
Chain 1: Iteration:  500 / 5000 [ 10%]  (Warmup)
Chain 1: Iteration: 1000 / 5000 [ 20%]  (Warmup)
Chain 1: Iteration: 1500 / 5000 [ 30%]  (Warmup)
Chain 1: Iteration: 2000 / 5000 [ 40%]  (Warmup)
Chain 1: Iteration: 2500 / 5000 [ 50%]  (Warmup)
Chain 1: Iteration: 2501 / 5000 [ 50%]  (Sampling)
Chain 1: Iteration: 3000 / 5000 [ 60%]  (Sampling)
Chain 1: Iteration: 3500 / 5000 [ 70%]  (Sampling)
Chain 1: Iteration: 4000 / 5000 [ 80%]  (Sampling)
Chain 1: Iteration: 4500 / 5000 [ 90%]  (Sampling)
Chain 1: Iteration: 5000 / 5000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 140.109 seconds (Warm-up)
Chain 1:                109.753 seconds (Sampling)
Chain 1:                249.862 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL 'dirichregmod' NOW (CHAIN 2).
Chain 2: Rejecting initial value:
Chain 2:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 2:   Stan can't start sampling from this initial value.
Chain 2: Rejecting initial value:
Chain 2:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 2:   Stan can't start sampling from this initial value.
Chain 2: Rejecting initial value:
Chain 2:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 2:   Stan can't start sampling from this initial value.
Chain 2: Rejecting initial value:
Chain 2:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 2:   Stan can't start sampling from this initial value.
Chain 2: Rejecting initial value:
Chain 2:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 2:   Stan can't start sampling from this initial value.
Chain 2: Rejecting initial value:
Chain 2:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 2:   Stan can't start sampling from this initial value.
Chain 2: Rejecting initial value:
Chain 2:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 2:   Stan can't start sampling from this initial value.
Chain 2: Rejecting initial value:
Chain 2:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 2:   Stan can't start sampling from this initial value.
Chain 2: 
Chain 2: Gradient evaluation took 0.002 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 20 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 5000 [  0%]  (Warmup)
Chain 2: Iteration:  500 / 5000 [ 10%]  (Warmup)
Chain 2: Iteration: 1000 / 5000 [ 20%]  (Warmup)
Chain 2: Iteration: 1500 / 5000 [ 30%]  (Warmup)
Chain 2: Iteration: 2000 / 5000 [ 40%]  (Warmup)
Chain 2: Iteration: 2500 / 5000 [ 50%]  (Warmup)
Chain 2: Iteration: 2501 / 5000 [ 50%]  (Sampling)
Chain 2: Iteration: 3000 / 5000 [ 60%]  (Sampling)
Chain 2: Iteration: 3500 / 5000 [ 70%]  (Sampling)
Chain 2: Iteration: 4000 / 5000 [ 80%]  (Sampling)
Chain 2: Iteration: 4500 / 5000 [ 90%]  (Sampling)
Chain 2: Iteration: 5000 / 5000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 168.262 seconds (Warm-up)
Chain 2:                113.358 seconds (Sampling)
Chain 2:                281.62 seconds (Total)
Chain 2: 

SAMPLING FOR MODEL 'dirichregmod' NOW (CHAIN 3).
Chain 3: Rejecting initial value:
Chain 3:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 3:   Stan can't start sampling from this initial value.
Chain 3: Rejecting initial value:
Chain 3:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 3:   Stan can't start sampling from this initial value.
Chain 3: Rejecting initial value:
Chain 3:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 3:   Stan can't start sampling from this initial value.
Chain 3: Rejecting initial value:
Chain 3:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 3:   Stan can't start sampling from this initial value.
Chain 3: Rejecting initial value:
Chain 3:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 3:   Stan can't start sampling from this initial value.
Chain 3: 
Chain 3: Gradient evaluation took 0.002 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 20 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 5000 [  0%]  (Warmup)
Chain 3: Iteration:  500 / 5000 [ 10%]  (Warmup)
Chain 3: Iteration: 1000 / 5000 [ 20%]  (Warmup)
Chain 3: Iteration: 1500 / 5000 [ 30%]  (Warmup)
Chain 3: Iteration: 2000 / 5000 [ 40%]  (Warmup)
Chain 3: Iteration: 2500 / 5000 [ 50%]  (Warmup)
Chain 3: Iteration: 2501 / 5000 [ 50%]  (Sampling)
Chain 3: Iteration: 3000 / 5000 [ 60%]  (Sampling)
Chain 3: Iteration: 3500 / 5000 [ 70%]  (Sampling)
Chain 3: Iteration: 4000 / 5000 [ 80%]  (Sampling)
Chain 3: Iteration: 4500 / 5000 [ 90%]  (Sampling)
Chain 3: Iteration: 5000 / 5000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 143.379 seconds (Warm-up)
Chain 3:                111.802 seconds (Sampling)
Chain 3:                255.181 seconds (Total)
Chain 3: 

SAMPLING FOR MODEL 'dirichregmod' NOW (CHAIN 4).
Chain 4: Rejecting initial value:
Chain 4:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 4:   Stan can't start sampling from this initial value.
Chain 4: Rejecting initial value:
Chain 4:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 4:   Stan can't start sampling from this initial value.
Chain 4: Rejecting initial value:
Chain 4:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 4:   Stan can't start sampling from this initial value.
Chain 4: Rejecting initial value:
Chain 4:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 4:   Stan can't start sampling from this initial value.
Chain 4: Rejecting initial value:
Chain 4:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 4:   Stan can't start sampling from this initial value.
Chain 4: Rejecting initial value:
Chain 4:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 4:   Stan can't start sampling from this initial value.
Chain 4: Rejecting initial value:
Chain 4:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 4:   Stan can't start sampling from this initial value.
Chain 4: Rejecting initial value:
Chain 4:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 4:   Stan can't start sampling from this initial value.
Chain 4: Rejecting initial value:
Chain 4:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 4:   Stan can't start sampling from this initial value.
Chain 4: Rejecting initial value:
Chain 4:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 4:   Stan can't start sampling from this initial value.
Chain 4: 
Chain 4: Gradient evaluation took 0.003 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 30 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 5000 [  0%]  (Warmup)
Chain 4: Iteration:  500 / 5000 [ 10%]  (Warmup)
Chain 4: Iteration: 1000 / 5000 [ 20%]  (Warmup)
Chain 4: Iteration: 1500 / 5000 [ 30%]  (Warmup)
Chain 4: Iteration: 2000 / 5000 [ 40%]  (Warmup)
Chain 4: Iteration: 2500 / 5000 [ 50%]  (Warmup)
Chain 4: Iteration: 2501 / 5000 [ 50%]  (Sampling)
Chain 4: Iteration: 3000 / 5000 [ 60%]  (Sampling)
Chain 4: Iteration: 3500 / 5000 [ 70%]  (Sampling)
Chain 4: Iteration: 4000 / 5000 [ 80%]  (Sampling)
Chain 4: Iteration: 4500 / 5000 [ 90%]  (Sampling)
Chain 4: Iteration: 5000 / 5000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 101.639 seconds (Warm-up)
Chain 4:                89.855 seconds (Sampling)
Chain 4:                191.494 seconds (Total)
Chain 4: 
```
```{r include=FALSE}
# save
if(!knitting){
saveRDS(fit_2_prey, here(resultsdir,'zoidOBJ_pReads_AllTaxa10plus_byCW_4ch5KiOD_2023-10-06.rds'))
}
# re-read input
if(knitting){
fit_2_prey <- readRDS(here(resultsdir,'zoidOBJ_pReads_AllTaxa10plus_byCW_4ch5KiOD_2023-10-06.rds'))
}
```

#### zoid output
Get the fitted values and label the species / sizes
```{r}
fitted_2 <- get_fitted(fit_2_prey)

## add in taxa / carapace width / crab id 
fitted_2 %<>% left_join(data.frame(group=seq(1:dim(data_matrix)[2]),
                                         taxon=colnames(data_matrix)), by=c("group"))

fitted_2 %<>% left_join(data.frame(obs=seq(1:dim(data_matrix)[1]),
                                   CW_mm=design_matrix[,1],
                                     crab_id=rownames(data_matrix)),by="obs")

## remove estimated values for taxa that didn't actually show up in the data for a given carapace width
fitted_2_filter <- fitted_2 %>%
  left_join(
    data_matrix %>% 
      rownames_to_column("crab_id") %>%
      pivot_longer(cols=2:(dim(data_matrix)[2]+1), names_to="taxon",values_to="reads"),
    by=c("crab_id","taxon")
  ) %>%
  filter(reads!=0)
```

Plot the fitted values
```{r}
if(!knitting){
  
png(here('figs',paste0('zoidMeansRaw_pReads_AllTaxa10plus_byCW_4ch5KiOD_2023-10-06.png')), res=300,height=2000,width=3000)
print(fitted_2_filter %>%
  group_by(taxon,CW_mm) %>%
  summarise(mean_cw=mean, upper_cw=lo,lower_cw=hi, n=length(unique(obs))) %>%
ggplot(aes(y=mean_cw,x=as.numeric(CW_mm))) +
    geom_point() + geom_errorbar(aes(ymin=lower_cw,ymax=upper_cw), width=0.25) + 
  geom_hline(aes(yintercept=0), color="gray60") +
  geom_text(aes(y=0.001,x=as.numeric(CW_mm),label=n)) +
    facet_wrap(~taxon, ncol=2, scales="free_y") + 
    labs(x="Carapace Width (mm)", y="Bayesian posterior mean", subtitle="Taxa present in 10+ crab") +
    theme_bw() +
    theme(axis.text.x=element_text(angle=45,hjust=1)))
dev.off()

}
```

compare the medians of the fitted values to the median read counts
```{r}
if(!knitting){
  
fitted_readsVest <- fitted_2_filter %>% 
  left_join(data_matrix %>% rownames_to_column("crab_id") %>% 
              pivot_longer(cols=2:(ncol(data_matrix)+1), names_to="taxon",values_to="preads")) %>%
  group_by(taxon,CW_mm) %>% 
  summarise(mean_preads=mean(preads),sd_preads=sd(preads), n=length(unique(crab_id))) %>%
  mutate(sd_preads=ifelse(is.na(sd_preads),0,sd_preads)) %>%
  left_join(fitted_2_filter %>% dplyr::select(CW_mm,mean,lo,hi,taxon) %>% distinct())

p1 <- ggplot(data=fitted_readsVest, aes(x=CW_mm,y=mean)) +
  geom_point() + geom_errorbar(aes(ymin=lo,ymax=hi), width=0.25) + 
  geom_hline(aes(yintercept=0)) +
  facet_grid(rows=vars(taxon), scales="free_y") +
  xlim(c(5, 20)) +
  theme_bw() + theme(strip.placement = "outside")

p2 <- ggplot(data=fitted_readsVest, aes(x=CW_mm,y=mean_preads)) +
  geom_point() + geom_errorbar(aes(ymin=mean_preads-sd_preads,ymax=mean_preads+sd_preads), width=0.25) + 
  geom_hline(aes(yintercept=0)) +
  facet_grid(rows=vars(taxon)) +
  ylim(c(0,1)) + xlim(c(5, 20)) +
  theme_bw() + theme(strip.placement = "inside")

png(here('figs','zoid_fittedVals_v_pReads_AllTaxa10plus_byCW_4ch5KiOD_2023-10-06.png'), res=300,height=4000,width=2000)
plot_grid(p1,p2,ncol=2)
dev.off()

}
```


Use the smallest crab size *for which the phylum was present* as the reference value (min possible = CW 5mm), and Get the difference between the value at carapace width X and the reference (so that if X > reference, difference is +)
```{r}
fitted_2_ref <- fitted_2_filter %>%
  # set the reference according to minimum CW in which that taxon was detected
  group_by(taxon) %>% mutate(min_cw=min(CW_mm)) %>% ungroup() %>%
  filter(CW_mm==min_cw) %>%
  dplyr::select(group,taxon,mean,median,lo,hi) %>% rename(ref_mean=mean,ref_median=median,ref_lo=lo,ref_hi=hi) %>%
  right_join(fitted_2_filter,by=c("group","taxon")) %>%
  # calculate change from reference
  mutate(scaled_mean=mean-ref_mean,
         scaled_median=median-ref_median,
         scaled_lo=lo-ref_lo,
         scaled_hi=hi-ref_hi)

fitted_2_ref %<>% 
  mutate(taxon=factor(taxon,levels=c("Naviculales","Dinophyceae","Balanus crenatus",
                                          "Euchlanis dilatata","Pleurosigma",
                                          "Chordariaceae","Micromonas pusilla","Monocorophium acherusicum", "Monocorophium insidiosum","Bacillariophyta","Bacillariophyceae")))
```

plot the relativized means without confidence intervals. remove values on the y axis other than zero.
```{r}
if(!knitting){
  
  
## plot for each taxon
png(here('figs',paste0('fig6_zoidMeansRelative_preads_AllTaxa10plus_4ch5KiOD_2023-10-06.png')), res=300,height=3000,width=2000)
print(ggplot(fitted_2_ref, aes(y=scaled_mean,x=as.numeric(CW_mm))) +
    geom_point() + geom_hline(aes(yintercept=0)) +
    facet_wrap(~taxon, ncol=2,dir="v",scales="free_y") + 
    labs(x="Carapace Width (CW; mm)", y="Difference from minimum CW") +
  ylim(c(-0.075,0.1)) +
    theme_bw() +
    theme(axis.text.x=element_text(angle=45,hjust=1)))
dev.off()

}
```

plot the relativized means with confidence intervals. remove values on the y axis other than zero.
```{r}
if(!knitting){
  
  
## plot for each taxon
png(here('figs',paste0('fig6_zoidMeansConfIntRelative_preads_AllTaxa10plus_4ch5KiOD_2023-10-06.png')), res=300,height=2600,width=1500)
print(ggplot(fitted_2_ref, aes(y=scaled_mean,x=as.numeric(CW_mm))) +
      geom_errorbar(aes(ymin=scaled_lo,ymax=scaled_hi),col="gray60",width=0.10) +
        geom_point(inherit.aes=TRUE) +
      geom_hline(aes(yintercept=0), color="gray60") +
    facet_wrap(~taxon, ncol=2,dir="v",scales="free_y") + 
    labs(x="Carapace Width (CW; mm)", y="Change from minimum CW") +
  scale_y_continuous(limits=c(-0.075,0.1)) +
    theme_bw() +
    theme(axis.text.x=element_text(angle=45,hjust=1)))
dev.off()

}
```



save out the data frame of fitted values
```{r}
if(!knitting){
write_csv(fitted_2_filter,here(resultsdir,paste0('zoidFittedValsFiltered_preads_AllTaxa10plus_4ch5KiOD_2023-10-06.csv')))
}
```




### all taxa, grouped by CW

sum up reads according to carapace width
```{r}
readsxCW.mat <- bind_rows(smdat,
                            dat %>% dplyr::select(-taxon) %>% rename(taxon=new_taxon)) %>%
  group_by(crab_id, taxon) %>% summarise(crabReads=sum(nReads),ntechs=length(unique(sample_id))) %>%
  mutate(crabReads_std=crabReads/ntechs) %>% 
  dplyr::select(-crabReads,ntechs) %>%
  pivot_wider(id_cols="crab_id", names_from="taxon",values_from="crabReads_std", values_fill=0) %>%
  left_join(cw.df,by="crab_id") %>%
  dplyr::select(-crab_id) %>%
  group_by(CW_mm) %>%
  summarise_if(is.numeric, sum) %>%
  column_to_rownames("CW_mm")

# remove rare taxa
readsxCW.mat <- dropspc(readsxCW.mat, minocc=1)
```

```{r}
zoidINxCW <- readsxCW.mat %>% rownames_to_column("CW_mm")

design_matrix = zoidINxCW[,which(names(zoidINxCW)=="CW_mm"), drop=FALSE]
data_matrix = zoidINxCW[,which(names(zoidINxCW)!="CW_mm")]
design_matrix$y = 1 # dummy variable

```

attempt to zoid!
```{r eval=FALSE}
fit_3_prey <- fit_zoid(formula = y ~ CW_mm, 
                      design_matrix = design_matrix, 
                      data_matrix = as.matrix(data_matrix)/10,
                       overdispersion = TRUE,
                       chains=4,
                       iter=5000)
```
```
SAMPLING FOR MODEL 'dirichregmod' NOW (CHAIN 1).
Chain 1: Rejecting initial value:
Chain 1:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 1:   Stan can't start sampling from this initial value.
Chain 1: Rejecting initial value:
Chain 1:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 1:   Stan can't start sampling from this initial value.
Chain 1: Rejecting initial value:
Chain 1:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 1:   Stan can't start sampling from this initial value.
Chain 1: Rejecting initial value:
Chain 1:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 1:   Stan can't start sampling from this initial value.
Chain 1: Rejecting initial value:
Chain 1:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 1:   Stan can't start sampling from this initial value.
Chain 1: Rejecting initial value:
Chain 1:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 1:   Stan can't start sampling from this initial value.
Chain 1: 
Chain 1: Gradient evaluation took 0.004 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 40 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 5000 [  0%]  (Warmup)
Chain 1: Iteration:  500 / 5000 [ 10%]  (Warmup)
Chain 1: Iteration: 1000 / 5000 [ 20%]  (Warmup)
Chain 1: Iteration: 1500 / 5000 [ 30%]  (Warmup)
Chain 1: Iteration: 2000 / 5000 [ 40%]  (Warmup)
Chain 1: Iteration: 2500 / 5000 [ 50%]  (Warmup)
Chain 1: Iteration: 2501 / 5000 [ 50%]  (Sampling)
Chain 1: Iteration: 3000 / 5000 [ 60%]  (Sampling)
Chain 1: Iteration: 3500 / 5000 [ 70%]  (Sampling)
Chain 1: Iteration: 4000 / 5000 [ 80%]  (Sampling)
Chain 1: Iteration: 4500 / 5000 [ 90%]  (Sampling)
Chain 1: Iteration: 5000 / 5000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 597.156 seconds (Warm-up)
Chain 1:                620.286 seconds (Sampling)
Chain 1:                1217.44 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL 'dirichregmod' NOW (CHAIN 2).
Chain 2: Rejecting initial value:
Chain 2:   Gradient evaluated at the initial value is not finite.
Chain 2:   Stan can't start sampling from this initial value.
Chain 2: Rejecting initial value:
Chain 2:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 2:   Stan can't start sampling from this initial value.
Chain 2: Rejecting initial value:
Chain 2:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 2:   Stan can't start sampling from this initial value.
Chain 2: Rejecting initial value:
Chain 2:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 2:   Stan can't start sampling from this initial value.
Chain 2: Rejecting initial value:
Chain 2:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 2:   Stan can't start sampling from this initial value.
Chain 2: Rejecting initial value:
Chain 2:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 2:   Stan can't start sampling from this initial value.
Chain 2: Rejecting initial value:
Chain 2:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 2:   Stan can't start sampling from this initial value.
Chain 2: 
Chain 2: Gradient evaluation took 0.005 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 50 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 5000 [  0%]  (Warmup)
Chain 2: Iteration:  500 / 5000 [ 10%]  (Warmup)
Chain 2: Iteration: 1000 / 5000 [ 20%]  (Warmup)
Chain 2: Iteration: 1500 / 5000 [ 30%]  (Warmup)
Chain 2: Iteration: 2000 / 5000 [ 40%]  (Warmup)
Chain 2: Iteration: 2500 / 5000 [ 50%]  (Warmup)
Chain 2: Iteration: 2501 / 5000 [ 50%]  (Sampling)
Chain 2: Iteration: 3000 / 5000 [ 60%]  (Sampling)
Chain 2: Iteration: 3500 / 5000 [ 70%]  (Sampling)
Chain 2: Iteration: 4000 / 5000 [ 80%]  (Sampling)
Chain 2: Iteration: 4500 / 5000 [ 90%]  (Sampling)
Chain 2: Iteration: 5000 / 5000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 589.694 seconds (Warm-up)
Chain 2:                616.284 seconds (Sampling)
Chain 2:                1205.98 seconds (Total)
Chain 2: 

SAMPLING FOR MODEL 'dirichregmod' NOW (CHAIN 3).
Chain 3: Rejecting initial value:
Chain 3:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 3:   Stan can't start sampling from this initial value.
Chain 3: Rejecting initial value:
Chain 3:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 3:   Stan can't start sampling from this initial value.
Chain 3: 
Chain 3: Gradient evaluation took 0.004 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 40 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 5000 [  0%]  (Warmup)
Chain 3: Iteration:  500 / 5000 [ 10%]  (Warmup)
Chain 3: Iteration: 1000 / 5000 [ 20%]  (Warmup)
Chain 3: Iteration: 1500 / 5000 [ 30%]  (Warmup)
Chain 3: Iteration: 2000 / 5000 [ 40%]  (Warmup)
Chain 3: Iteration: 2500 / 5000 [ 50%]  (Warmup)
Chain 3: Iteration: 2501 / 5000 [ 50%]  (Sampling)
Chain 3: Iteration: 3000 / 5000 [ 60%]  (Sampling)
Chain 3: Iteration: 3500 / 5000 [ 70%]  (Sampling)
Chain 3: Iteration: 4000 / 5000 [ 80%]  (Sampling)
Chain 3: Iteration: 4500 / 5000 [ 90%]  (Sampling)
Chain 3: Iteration: 5000 / 5000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 569.183 seconds (Warm-up)
Chain 3:                626.436 seconds (Sampling)
Chain 3:                1195.62 seconds (Total)
Chain 3: 

SAMPLING FOR MODEL 'dirichregmod' NOW (CHAIN 4).
Chain 4: Rejecting initial value:
Chain 4:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 4:   Stan can't start sampling from this initial value.
Chain 4: Rejecting initial value:
Chain 4:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 4:   Stan can't start sampling from this initial value.
Chain 4: Rejecting initial value:
Chain 4:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 4:   Stan can't start sampling from this initial value.
Chain 4: Rejecting initial value:
Chain 4:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 4:   Stan can't start sampling from this initial value.
Chain 4: Rejecting initial value:
Chain 4:   Log probability evaluates to log(0), i.e. negative infinity.
Chain 4:   Stan can't start sampling from this initial value.
Chain 4: 
Chain 4: Gradient evaluation took 0.003 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 30 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 5000 [  0%]  (Warmup)
Chain 4: Iteration:  500 / 5000 [ 10%]  (Warmup)
Chain 4: Iteration: 1000 / 5000 [ 20%]  (Warmup)
Chain 4: Iteration: 1500 / 5000 [ 30%]  (Warmup)
Chain 4: Iteration: 2000 / 5000 [ 40%]  (Warmup)
Chain 4: Iteration: 2500 / 5000 [ 50%]  (Warmup)
Chain 4: Iteration: 2501 / 5000 [ 50%]  (Sampling)
Chain 4: Iteration: 3000 / 5000 [ 60%]  (Sampling)
Chain 4: Iteration: 3500 / 5000 [ 70%]  (Sampling)
Chain 4: Iteration: 4000 / 5000 [ 80%]  (Sampling)
Chain 4: Iteration: 4500 / 5000 [ 90%]  (Sampling)
Chain 4: Iteration: 5000 / 5000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 595.84 seconds (Warm-up)
Chain 4:                607.274 seconds (Sampling)
Chain 4:                1203.11 seconds (Total)
Chain 4: 
```


```{r include=FALSE}
if(!knitting){
saveRDS(fit_3_prey, here('data','results','zoid_AllTaxa_GroupedByCW_4chains50K.rds'))
}
if(knitting){
fit_3_prey <- readRDS(here('data','results','zoidOBJ_AllTaxa_GroupedByCW_4chains50K.rds'))
}
```



Get the fitted values and label the species / sizes
```{r}
fitted_3 <- get_fitted(fit_3_prey)

## add in species / carapace width
fitted_3 %<>% left_join(data.frame(group=seq(1:dim(data_matrix)[2]),
                                         species=colnames(data_matrix)), by=c("group"))

fitted_3 %<>% left_join(data.frame(obs=seq(1:dim(data_matrix)[1]),
                                   CW_mm=design_matrix[,1]),by="obs")

## remove estimated values for taxa that didn't actually show up in the data for a given carapace width
fitted_3_filter <- fitted_3 %>%
  left_join(
    bind_cols(design_matrix,data_matrix) %>% 
      pivot_longer(cols=2:(dim(data_matrix)[2]+2), names_to="species",values_to="reads")
  ) %>%
  filter(CW_mm==5 | (CW_mm!=5 & reads!=0))
```



Use the smallest crab size as the reference value (CW 5mm)
```{r}
fitted_3_ref <- fitted_3_filter %>%
  mutate(mean=ifelse(CW_mm==5 & reads==0, 0, mean),
         median=ifelse(CW_mm==5 & reads==0, 0, median)) %>%
  filter(CW_mm==5) %>%
  dplyr::select(group,species,mean,median) %>% rename(ref_mean=mean,ref_median=median) %>%
  right_join(fitted_3_filter,by=c("group","species")) %>%
  mutate(mean=ifelse(CW_mm==5 & reads==0, 0, mean),
         median=ifelse(CW_mm==5 & reads==0, 0, median))
```

Get the difference between the value at carapace width X and the reference (so that if X > reference, difference is +)
```{r}
fitted_3_ref %<>% mutate(diff_mean=mean-ref_mean,
                     diff_median=median-ref_median)
```

```{r}
## add taxonomy
fitted_3_ref %<>% left_join(bind_rows(dat, smdat %>% mutate(new_taxon=taxon)) %>%
                          dplyr::select(new_taxon,phylum,class,order,family,genus,species) %>%
                          distinct(), by=c("species"="new_taxon"))

## remove estimated values for taxa that didn't actually show up in the data for a given carapace width


## plot for each phylum 
for(p in unique(fitted_3_ref$phylum)){
  if(!is.na(p)){
  tmp <- ggplot(fitted_3_ref %>% filter(phylum==p), aes(y=diff_mean,x=as.numeric(CW_mm))) +
    geom_point() + geom_hline(aes(yintercept=0)) +
    facet_wrap(~species, scales="free_y") + 
    labs(x="Carapace Width (mm)", y="Difference from 5mm CW", subtitle=p) +
    theme_bw() +
    theme(axis.text.x=element_text(angle=45,hjust=1))
  png(here(resultsdir,paste0('zoid_AllTaxa_GroupedByCW_4chains50K_',p,'.png')), res=300,height=2000,width=3000)
  print(tmp)
  dev.off()
  } else{
    tmp <- ggplot(fitted_3_ref %>% filter(is.na(phylum)), aes(y=diff_mean,x=as.numeric(CW_mm))) +
    geom_point() + geom_hline(aes(yintercept=0)) +
    facet_wrap(~species, scales="free_y") + 
    labs(x="Carapace Width (mm)", y="Difference from 5mm CW", subtitle=p) +
    theme_bw() +
    theme(axis.text.x=element_text(angle=45,hjust=1))
    
    if(!knitting){
  png(here(resultsdir,paste0('zoid_AllTaxa_GroupedByCW_4chains50K_',p,'.png')), res=300,height=2000,width=3000)
  print(tmp)
  dev.off()
    }
  }
}
```




## GLM


### just on distances
Is there a correlation between the Bray-Curtis distance and the difference in carapace width between every pair of samples? 


Calculate the differences in carapace width between each sample. What does the distribution look like?
```{r}
cw_diffs <- abs(outer(cw.df$CW_mm, cw.df$CW_mm, FUN = "-"))
colnames(cw_diffs) <- cw.df$crab_id; rownames(cw_diffs) <- cw.df$crab_id
```

```{r echo=FALSE}
cw_diffs.df <- cw_diffs %>%
  as.data.frame() %>%
  rownames_to_column("crab_id") %>%
  pivot_longer(cols=2:(dim(cw_diffs)[2]+1), names_to="crab_id_2",values_to="CW_diff")

ggplot(cw_diffs.df, aes(x=CW_diff)) + 
  geom_histogram(aes(y=after_stat(density))) +
  labs(x="Difference in Carapace Width (mm)", y="density") + theme_bw()
```

Calculate the distances between each sample's prey composition (eDNA index, bray-curtis distance)
```{r}
# get rid of rare prey items that only occur in one crab
index.mat.filter <- dropspc(index.mat2, minocc=2)
index.mat.filter <- index.mat.filter[which(rowSums(index.mat.filter) > 0),]

dim(index.mat2); dim(index.mat.filter)


# calculate bray-curtis distance
index.bc <- vegdist(index.mat.filter, method="bray")
```

Here is what the distance matrix values look like:
```{r echo=FALSE, fig.height=4, fig.width=4}
as.matrix(index.bc) %>%
  as.data.frame() %>%
  rownames_to_column("crab_id") %>%
  pivot_longer(cols=2:(dim(as.matrix(index.bc))[2]+1), names_to="crab_id_2",values_to="BCdistance") %>%
  ggplot(aes(x=BCdistance)) + 
  geom_histogram(aes(y=after_stat(density))) + 
  labs(x="Bray-Curtis Distance",y="density") +theme_bw()
```

combine the differences / distances into one data frame.
```{r}
reg.in <- as.matrix(index.bc) %>%
  as.data.frame() %>%
  rownames_to_column("crab_id") %>%
  pivot_longer(cols=2:(dim(as.matrix(index.bc))[2]+1), names_to="crab_id2",values_to="BCdistance") %>%
  left_join(
    cw_diffs %>%
      as.data.frame() %>%
      rownames_to_column("crab_id") %>%
      pivot_longer(cols=2:(dim(cw_diffs)[2]+1), names_to="crab_id2",values_to="CW_diff"),
    by=c("crab_id","crab_id2"))
```

What do they look like plotted against each other?
```{r}
ggplot(reg.in,aes(x=CW_diff,y=BCdistance)) +
  geom_point() + labs(x="Difference in Carapace Width (mm)", y="Bray-Curtis Distance") +
  theme_bw()
```

Use a generalized linear model to correlate the carapace width differences with the distance values (quasi-binomial, logit-link -- bray-curtis distances are between 0 and 1, left skewed)
```{r}
cw.glm <- glm(BCdistance ~ CW_diff, data = reg.in, family = quasibinomial('logit'))
summary(cw.glm)
```

```
Call:
glm(formula = BCdistance ~ CW_diff, family = quasibinomial("logit"), 
    data = reg.in)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.9574  -0.0908   0.2079   0.4182   0.5644  

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  1.75653    0.04609   38.11   <2e-16 ***
CW_diff      0.13223    0.01556    8.50   <2e-16 ***


(Dispersion parameter for quasibinomial family taken to be 0.274319)

Null deviance: 791.97  on 3363  degrees of freedom
Residual deviance: 770.65  on 3362  degrees of freedom
AIC: NA

Number of Fisher Scoring iterations: 5
```

Address potential heteroskedasticity of errors:
```{r}
robust.se.glm1 <- sqrt(diag(vcovHC(cw.glm , type="HC0")))
coeftest(cw.glm, vcovHC(cw.glm , type="HC0"))
```

Diagnostics
```{r}
plot(cw.glm)
```

compare deviance
```{r}
null <- 792/3363
resid <- 771/3362

(null-resid)/null
```



### spatial x CW 

#### add estuary / site

Determine whether each pair of crabs come from the same (1) or different (0) estuary. Save this information in the `reg.in2` dataframe
```{r}
reg.in2 <- reg.in

# add estuary / site for each crab in the pair
reg.in2 %<>% left_join(dplyr::select(lab_metadat,sample_id,estuary,sampling_location), by=c("crab_id"="sample_id")) %>% 
  rename(estuary1=estuary, site1=sampling_location) %>%
  left_join(dplyr::select(lab_metadat,sample_id,estuary,sampling_location), by=c("crab_id2"="sample_id")) %>% 
  rename(estuary2=estuary, site2=sampling_location)

# make PBNERR crab from the same site
reg.in2 %<>% mutate(site1=ifelse(grepl("PBNERR", site1), "PBNERR", site1),
                    site2=ifelse(grepl("PBNERR", site2), "PBNERR",site2))

# code same or different estuary / site
reg.in2 %<>% mutate(estuary=ifelse(estuary1==estuary2, 1, 0),
                    site=ifelse(site1==site2,1,0))

colnames(reg.in2)
```

How does this interact with carapace width differences?
```{r fig.height=3, fig.width=3}
reg.in2 %>% mutate(site=as.factor(site),estuary=as.factor(estuary)) %>%
ggplot( aes(y=CW_diff,x=site, fill=estuary)) + 
  geom_boxplot() + theme_bw()
```


#### run set of models

Diet Difference ~ Change in CW 
```{r}
cw.glm <- glm(BCdistance ~ CW_diff, data = reg.in2, family = quasibinomial('logit'))
```

Diet Difference ~ Estuary  ; Diet Difference ~ Change in CW + Estuary  ; Diet Difference ~ Change in CW * Estuary
```{r}
est.glm <- glm(BCdistance ~ estuary, data = reg.in2, family = quasibinomial('logit'))

cw.est.glm1 <- glm(BCdistance ~ CW_diff + estuary, data = reg.in2, family = quasibinomial('logit'))

cw.est.glm2 <- glm(BCdistance ~ CW_diff * estuary, data = reg.in2, family = quasibinomial('logit'))
```

Diet Difference ~ Site ;  Diet Difference ~ Change in CW + Site  ;   Diet Difference ~ Change in CW * Site
```{r}
site.glm <- glm(BCdistance ~  site, data = reg.in2, family = quasibinomial('logit'))

cw.site.glm1 <- glm(BCdistance ~ CW_diff + site, data = reg.in2, family = quasibinomial('logit'))

cw.site.glm2 <- glm(BCdistance ~ CW_diff * site, data = reg.in2, family = quasibinomial('logit'))
```

```{r}
anova(cw.glm,cw.est.glm1,cw.est.glm2, test="F") #also checked with LRT
anova(est.glm,cw.est.glm1,cw.est.glm2, test="F") #also checked with LRT
```


```{r}
anova(cw.glm,cw.site.glm1,cw.site.glm2, test="F") #also checked with LRT
anova(site.glm,cw.site.glm1,cw.site.glm2, test="F") #also checked with LRT
```




## Beta Reg

Is there a correlation between the Bray-Curtis distance and the difference in carapace width between every pair of samples? 


Calculate the differences in carapace width between each sample. What does the distribution look like?
```{r}
cw_diffs <- abs(outer(cw.df$CW_mm, cw.df$CW_mm, FUN = "-"))
colnames(cw_diffs) <- cw.df$crab_id; rownames(cw_diffs) <- cw.df$crab_id
```

```{r echo=FALSE}
cw_diffs.df <- cw_diffs %>%
  as.data.frame() %>%
  rownames_to_column("crab_id") %>%
  pivot_longer(cols=2:(dim(cw_diffs)[2]+1), names_to="crab_id_2",values_to="CW_diff")

ggplot(cw_diffs.df, aes(x=CW_diff)) + 
  geom_histogram(aes(y=after_stat(density))) +
  labs(x="Difference in Carapace Width (mm)", y="density") + theme_bw()
```

Calculate the distances between each sample's prey composition (eDNA index, bray-curtis distance)
```{r}
# get rid of rare prey items that only occur in one crab
index.mat.filter <- dropspc(index.mat2, minocc=2)
index.mat.filter <- index.mat.filter[which(rowSums(index.mat.filter) > 0),]

dim(index.mat2); dim(index.mat.filter)


# calculate bray-curtis distance
index.bc <- vegdist(index.mat.filter, method="bray")
```

Here is what the distance matrix values look like:
```{r echo=FALSE, fig.height=4, fig.width=4}
as.matrix(index.bc) %>%
  as.data.frame() %>%
  rownames_to_column("crab_id") %>%
  pivot_longer(cols=2:(dim(as.matrix(index.bc))[2]+1), names_to="crab_id_2",values_to="BCdistance") %>%
  ggplot(aes(x=BCdistance)) + 
  geom_histogram(aes(y=after_stat(density))) + 
  labs(x="Bray-Curtis Distance",y="density") +theme_bw()
```

combine the differences / distances into one data frame.
```{r}
reg.in <- as.matrix(index.bc) %>%
  as.data.frame() %>%
  rownames_to_column("crab_id") %>%
  pivot_longer(cols=2:(dim(as.matrix(index.bc))[2]+1), names_to="crab_id2",values_to="BCdistance") %>%
  left_join(
    cw_diffs %>%
      as.data.frame() %>%
      rownames_to_column("crab_id") %>%
      pivot_longer(cols=2:(dim(cw_diffs)[2]+1), names_to="crab_id2",values_to="CW_diff"),
    by=c("crab_id","crab_id2"))
```

What do they look like plotted against each other?
```{r}
ggplot(reg.in,aes(x=CW_diff,y=BCdistance)) +
  geom_point() + labs(x="Difference in Carapace Width (mm)", y="Bray-Curtis Distance") +
  theme_bw()
```

Use a generalized linear model to correlate the carapace width differences with the distance values (quasi-binomial, logit-link -- bray-curtis distances are between 0 and 1, left skewed)
```{r}
cw.beta <- betareg(BCdistance ~ CW_diff, data = reg.in, link = "logit")
summary(cw.beta)
```


## CCA 

### All Taxa

Use the eDNA index values to conduct a canonical correlation analysis. 

#### run CCA

Drop rare species (occur in < `mo` crab) 
```{r}
mo <- 9
crabID.index.filter.mat <- dropspc(as.matrix(index.df2[,5:dim(index.df2)[2]]), minocc=mo)
# add row names back on
rownames(crabID.index.filter.mat) <- index.df2$crab_id
crabID.index.filter.mat <- crabID.index.filter.mat[which(rowSums(crabID.index.filter.mat) > 0),]

dim(crabID.index.filter.mat)
```

add carapace widths
```{r}
crabID.index.filter.df <- as.data.frame(crabID.index.filter.mat) %>%
  rownames_to_column(var="crab_id") %>%
  left_join(cw.df,by="crab_id")

n <- dim(crabID.index.filter.df)[2]
```

run CCA
```{r}
set.seed(555)
cc1 <- cca(X=as.matrix(crabID.index.filter.df[,2:(n-1)]), Y=crabID.index.filter.df[,n, drop=FALSE])
plot(cc1)
```

```{r}
set.seed(555)
anova(cc1,permutations = how(nperm=10000))
```


### plot CCA

extract CCA1 / CA1 scores and the biplot from the CCA object.
```{r}
cc1.obj <- fortify(cc1)

cc1.sites <- cc1.obj %>% filter(score=="sites") %>% dplyr::select(label,CCA1,CA1) %>% 
  mutate(CCA1=as.numeric(CCA1), CA1=as.numeric(CA1)) %>%
  mutate(crab_id=as.character(crabID.index.filter.df[,1])) %>%
  left_join(dplyr::select(index.df2, crab_id, site, estuary) %>% distinct(), by="crab_id")

cc1.species <- cc1.obj %>% filter(score=="species") %>% dplyr::select(label,CCA1,CA1) %>% 
  mutate(CCA1=as.numeric(CCA1), CA1=as.numeric(CA1))

want <- cc1.obj$score == "biplot"
cc1.biplot <- as.data.frame(cc1.obj[want, , drop = FALSE ]) %>%
  mutate(label="Carapace\nwidth")
```

plot

```{r}
ggplot(cc1.sites,aes(x=CCA1,y=CA1,color=estuary)) + 
  geom_point() + 
  geom_text(data=cc1.species,aes(x=CCA1,y=CA1, label=label), inherit.aes = FALSE) +
  geom_point(data=cc1.species,aes(x=CCA1,y=CA1), pch=1, inherit.aes = FALSE) +
  geom_segment(data=cc1.biplot,aes(x=0,y=0,xend=cc1.biplot$CCA1*4,yend=cc1.biplot$CA1),
               arrow = arrow(length = unit(0.2, "cm")),
                         colour = "darkblue", inherit.aes = FALSE) +
  geom_text(data = cc1.biplot,aes_string(x = cc1.biplot$CCA1*3.5, y = cc1.biplot$CA1+0.3, label = "label"), 
            colour = "darkblue", inherit.aes = FALSE) +
   theme_bw()
```


Only label the species with the highest / lowest CCA1 scores -- outside the 99% confidence interval

```{r}
tmp.lm <- lm(CCA1 ~ 1,data=cc1.species)
ci99.species <- confint(tmp.lm,level=0.99)

lowest_cca <- cc1.species %>% filter(CCA1 < ci99.species[1]) %>% arrange(CCA1) %>% pull(label)
highest_cca <- cc1.species %>% filter(CCA1 > ci99.species[2]) %>% arrange(CCA1) %>% pull(label)
```

```{r}
cc1.sites %<>% rename(Estuary=estuary)
plot.99ci <- ggplot(cc1.species,aes(x=CCA1,y=CA1)) + 
  geom_point(data=cc1.sites,aes(x=CCA1,y=CA1,color=Estuary), pch=1,inherit.aes = FALSE) +
  geom_point(pch=16) + 
  geom_text_repel(data=filter(cc1.species, label %in% highest_cca),
                  aes(x=CCA1,y=CA1, label=label), 
                  min.segment.length=0.01,ylim=c(2,4),inherit.aes = FALSE) +
  geom_point(data=filter(cc1.species, label %in% highest_cca),
                  aes(x=CCA1,y=CA1), pch=15,size=2,inherit.aes = FALSE) +
  geom_text_repel(data=filter(cc1.species, label %in% lowest_cca) %>% mutate(label2=paste0("italic('",label,"')")),
                  aes(x=CCA1,y=CA1, label=label2), 
                  min.segment.length=0.01, nudge_y=-1,nudge_x=-0.75,inherit.aes = FALSE,parse=TRUE) +
  geom_point(data=filter(cc1.species, label %in% lowest_cca),
                  aes(x=CCA1,y=CA1),pch=15,size=2,inherit.aes = FALSE) +
  geom_segment(data=cc1.biplot,aes(x=0,y=0,xend=cc1.biplot$CCA1*3,yend=cc1.biplot$CA1),
               arrow = arrow(length = unit(0.2, "cm")),
                         colour = "gray50", inherit.aes = FALSE) +
  geom_text(data = cc1.biplot,aes_string(x = cc1.biplot$CCA1*1.7, y = cc1.biplot$CA1+0.45, label = "label"), 
            colour = "gray50", inherit.aes = FALSE) +
  xlim(c(-3.5, 3.5)) +
   theme_bw()
plot.99ci
```


```{r}
if(!knitting){
  
png(here('figs','Fig4_CCA_AllTaxa10plus_v_CW_label99CI.png'), res=300,width=1700,height=1400)
print(plot.99ci)
dev.off()

}
```



## Sparse partial least squares analysis


Djurhuus et al. :

> In order to directly associate specific taxa to environmental variables (Fig. 3), we used sparse partial least square (sPLS) analysis from the R package mixOmics. We applied the sPLS in regression mode, which will model a causal relationship between the lineages and the environmental traits, that is, PLS will predict environmental traits (e.g., temperature) from lineage abundances. This approach enabled us to identify strong correlations between certain taxa and environmental variables without taking into account the global structure of the planktonic community.


I don't see a good linear correlation between carapace width and crab diet. 


### quick start

samples as rows, species as columns. "expression measure" = eDNA index

```{r}
mixin <- as.matrix(index.df2[,5:dim(index.df2)[2]])
rownames(mixin) <- index.df2$crab_id

# remove species present in < 3 crab
mixin <- dropspc(mixin, minocc=5)
# make sure all crabs still have species
mixin <- mixin[which(rowSums(mixin) > 0),]

dim(mixin)
```

```{r}
MyResult.pca <- pca(mixin)  # 1 Run the method
plotIndiv(MyResult.pca) # 2 Plot the samples
plotVar(MyResult.pca) # 3 Plot the variables
```


### sPLS1

```{r}
x <- mixin

y <- as.matrix(data.frame(crab_id=rownames(mixin)) %>%
  left_join(cw.df, by="crab_id") %>%
  column_to_rownames("crab_id"))


all(rownames(mixin) == rownames(y))
```
Defining the best number of dimensions to explain the data requires we first launch a PLS1 model with a large number of components. Some of the outputs from the PLS1 object are then retrieved in the perf() function to calculate the Q2 criterion using repeated 10-fold cross-validation.
```{r}
cw.pls1 <- pls(X = mixin, Y = y, ncomp = 4, mode = 'regression')
set.seed(33)  # For reproducibility with this handbook, remove otherwise
Q2.cw.pls1 <- perf(cw.pls1, validation = 'Mfold', 
                      folds = 10, nrepeat = 5)
plot(Q2.cw.pls1, criterion = 'Q2')
```


Ideally, one of these would be above the '0' line...

```{r}
cor(cw.pls1$variates$X, cw.pls1$variates$Y)
```

```{r}
data.frame(x=cw.pls1$variates$X,
                  y=cw.pls1$variates$Y,
                  cw=y[,1]) %>%
  ggplot(aes(x=x.comp2,y=y.comp2,color=cw)) + 
  geom_point() +
  geom_point(aes(x=x.comp1,y.comp1,color=cw), inherit.aes=FALSE) +
  labs(x = 'X component', y = 'y component / scaled y') + theme_bw()
```


#### tuning

We now set a grid of values - thin at the start, but also restricted to a small number of genes for a parsimonious model, which we will test for each of the two components in the tune.spls() function, using the MAE criterion.
```{r}
# Set up a grid of values: 
list.keepX <- c(1:10, c(15,20,25,28))     

# list.keepX  # Inspect the keepX grid
set.seed(33)  # For reproducibility with this handbook, remove otherwise
tune.spls1.MAE <- tune.spls(x, y, ncomp= 2, 
                            test.keepX = list.keepX, 
                            validation = 'Mfold', 
                            folds = 10,
                            nrepeat = 5, 
                            progressBar = FALSE, 
                            measure = 'MAE')
plot(tune.spls1.MAE)
```
```{r}
set.seed(33)  # For reproducibility with this handbook, remove otherwise
tune.spls1.MSE <- tune.spls(x, y, ncomp= 2, 
                            test.keepX = list.keepX, 
                            validation = 'Mfold', 
                            folds = 10,
                            nrepeat = 5, 
                            progressBar = FALSE, 
                            measure = 'MSE')
plot(tune.spls1.MSE)
```

```{r} 
set.seed(33)  # For reproducibility with this handbook, remove otherwise
tune.spls1.R <- tune.spls(x, y, ncomp= 2, 
                            test.keepX = list.keepX, 
                            validation = 'Mfold', 
                            folds = 10,
                            nrepeat = 5, 
                            progressBar = FALSE, 
                            measure = 'R2')
plot(tune.spls1.R)
```

```{r}
set.seed(33)  # For reproducibility with this handbook, remove otherwise
tune.spls1.B <- tune.spls(x, y, ncomp= 2, 
                            test.keepX = list.keepX, 
                            validation = 'Mfold', 
                            folds = 10,
                            nrepeat = 5, 
                            progressBar = FALSE, 
                            measure = 'Bias')
plot(tune.spls1.B)
```


Based on the tune.spls() function we extract the final parameters:
```{r eval=FALSE}
choice.ncomp.MAE <- tune.spls1.MAE$choice.ncomp$ncomp
# Optimal number of variables to select in X based on the MAE criterion
# We stop at choice.ncomp
choice.keepX.MAE <- tune.spls1.MAE$choice.keepX[1:choice.ncomp]  

choice.ncomp.MAE

choice.keepX.MAE
```
```{r eval=FALSE}
choice.ncomp.B <- tune.spls1.B$choice.ncomp$ncomp
# Optimal number of variables to select in X based on the MAE criterion
# We stop at choice.ncomp
choice.keepX.B <- tune.spls1.B$choice.keepX[1:choice.ncomp]  

choice.ncomp.B

choice.keepX.B
```

#### final model
Here is our final model with the tuned parameters:
```{r eval=FALSE}
spls1.cw <- spls(x, y, ncomp = choice.ncomp.B, keepX = c(rep(choice.keepX.B,2)), 
                    mode = "regression")
```

The list of genes selected on component 1 can be extracted with the command line (not output here):
```{r eval=FALSE}
selectVar(spls1.cw, comp = 1)$X$name
selectVar(spls1.cw, comp = 2)$X$name
```

We can compare the amount of explained variance for the X data set based on the sPLS1 (on 1 component) versus PLS1 (that was run on 4 components during the tuning step):
```{r eval=FALSE}
spls1.cw$prop_expl_var$X

cw.pls1$prop_expl_var$X
```

The amount of explained variance in X is lower in sPLS1 than PLS1 for the first component. 

Is the Mean Squared Error Prediction is also lower (better) in sPLS1 compared to PLS1?

#### sample plots

plot each sample (crab) across the two components (x/y axis, selected with ncomp) for the "X" data set of prey items, and the "Y" data set of carapace widths.

```{r eval=FALSE}
plotIndiv(spls1.cw,
          group = y[,1], legend=TRUE)
```

plot each sample (crab) for both y / both x components: a reduced representation of a multivariate regression

```{r eval=FALSE}
data.frame(x=spls1.cw$variates$X,
                  y=spls1.cw$variates$Y,
                  cw=y[,1],
           label=rownames(y)) %>%
  ggplot(aes(x=x.comp2,y=y.comp2,color=cw)) + 
  geom_point() +
  # geom_label(aes(label=label)) +
  geom_point(aes(x=x.comp1,y.comp1,color=cw), inherit.aes=FALSE) +
  labs(x = 'X component', y = 'y component / scaled y') + theme_bw()
```

Does PLS1 effectively models a linear relationship between carapace width and the combination of the two prey items selected in X.? This doesn't look much like a linear correlation - maybe if you removed all of those crabs lined up below 0 on the x component.


```{r eval=FALSE}
selectVar(spls1.cw, comp = 1)$X$name
cor(spls1.cw$variates$X, spls1.cw$variates$Y)


selectVar(spls1.cw, comp = 2)$X$name
cor(spls1.cw$variates$X, spls1.cw$variates$Y)
```

correlation between carapace width and the diet data when "Cryptophyceae" and "Fucus distichus" are used in the regression: 0.44

Correlation when "Naviculales" and "Nitzschia" are used in the regression: 0.3


Run this in the console. It gives the crab clustered on the y axis, the two x 2 components species on the x axis, and heatmap colors for correlation. 
```{r eval=FALSE}
cim(spls1.cw, comp = 1:2, xlab = "prey", ylab = "crab",
# To save the plot, uncomment:
# save = 'pdf', name.save = 'cim_liver'
)
```

ok, here we can see why the regression is crap. only about 15 crab actually have these two species (the rest of the heatmap values are zero). so the remaining crab can't have their diet explained by the data. If I dig into the labels, these are the crab with an x component > 0 on the scatterplot above.








## Parking Lot

### CCA viz
Only label the species with the highest / lowest CCA1 scores -- the top 2 species

```{r eval=FALSE}
lowest2_cca <- cc1.species %>% top_n(n=2,wt=desc(CCA1)) %>% pull(label)
highest2_cca <- cc1.species %>% top_n(n=2,wt=CCA1) %>% arrange(CCA1) %>% pull(label)


plot.top2 <- ggplot(cc1.species,aes(x=CCA1,y=CA1)) + 
  geom_point(data=cc1.sites,aes(x=CCA1,y=CA1,color=estuary), pch=1,inherit.aes = FALSE) +
  geom_point(pch=16) + 
  geom_text_repel(data=filter(cc1.species, label %in% highest2_cca),
                  aes(x=CCA1,y=CA1, label=label), 
                  min.segment.length=0.01,ylim=c(2,4),inherit.aes = FALSE) +
  geom_point(data=filter(cc1.species, label %in% highest2_cca),
                  aes(x=CCA1,y=CA1), pch=15,size=2,inherit.aes = FALSE) +
  geom_text_repel(data=filter(cc1.species, label %in% lowest2_cca) %>% mutate(label2=paste0("italic('",label,"')")),
                  aes(x=CCA1,y=CA1, label=label2), 
                  min.segment.length=0.01, nudge_y=-1,nudge_x=-0.75,inherit.aes = FALSE,parse=TRUE) +
  geom_point(data=filter(cc1.species, label %in% lowest2_cca),
                  aes(x=CCA1,y=CA1),pch=15,size=2,inherit.aes = FALSE) +
  geom_segment(data=cc1.biplot,aes(x=0,y=0,xend=cc1.biplot$CCA1*3,yend=cc1.biplot$CA1),
               arrow = arrow(length = unit(0.2, "cm")),
                         colour = "gray50", inherit.aes = FALSE) +
  geom_text(data = cc1.biplot,aes_string(x = cc1.biplot$CCA1*1.7, y = cc1.biplot$CA1+0.3, label = "label"), 
            colour = "gray50", inherit.aes = FALSE) +
  xlim(c(-3.5, 3.5)) +
   theme_bw()
plot.top2
```



```{r eval=FALSE}
if(!knitting){
  
png(here('figs','Fig4_CCA_AllTaxa10plus_v_CW_labeltop2.png'), res=300,width=2100,height=1500)
plot.top2
dev.off()

}
```


### ZOID with raw reads INCORRECT

Remove taxa that occur in fewer than ten crab (not super useful for comparing across sizes). the function `dropspc` assumes that the species are in columns of the matrix. Otherwise, **zoid will not run**
```{r eval=FALSE}
crabID.reads.filter.mat <- dropspc(crabID.reads.mat, minocc=9)
crabID.reads.filter.mat <- crabID.reads.filter.mat[which(rowSums(crabID.reads.filter.mat) > 0),]

dim(crabID.reads.mat); dim(crabID.reads.filter.mat)
```


join with carapace widths
```{r eval=FALSE}
zoidIN.reads <- crabID.reads.filter.mat %>%
  rownames_to_column("crab_id") %>%
  left_join(cw.df,by="crab_id") %>%
  column_to_rownames("crab_id")



any(is.na(zoidIN.reads$CW_mm))
```


create the design matrix (site / site type information per observation, aka per crab) and the data matrix (read counts only)
```{r eval=FALSE}
design_matrix = zoidIN.reads[,which(names(zoidIN.reads)=="CW_mm"), drop=FALSE]
data_matrix = zoidIN.reads[,which(names(zoidIN.reads)!="CW_mm")]
design_matrix$y = 1 # dummy variable
```

attempt to zoid!
```{r eval=FALSE}
fit_1_prey <- fit_zoid(formula = y ~ CW_mm, 
                       design_matrix = design_matrix, 
                       data_matrix = as.matrix(data_matrix)/1000,
                       overdispersion = TRUE,
                       chains=4,
                       iter=5000,
                       overdispersion_sd = 0.1)
```


save data
```{r eval=FALSE}
saveRDS(fit_1_prey,here(resultsdir,'zoidOUT_nReads_allTaxa10plus_by_CW.rds'))
```


Get the fitted values and label the species / sizes
```{r eval=FALSE}
fitted_1 <- get_fitted(fit_1_prey)

## add in taxa / carapace width / crab id 
fitted_1 %<>% left_join(data.frame(group=seq(1:dim(data_matrix)[2]),
                                         taxon=colnames(data_matrix)), by=c("group"))

fitted_1 %<>% left_join(data.frame(obs=seq(1:dim(data_matrix)[1]),
                                   CW_mm=design_matrix[,1],
                                     crab_id=rownames(data_matrix)),by="obs")

## remove estimated values for taxa that didn't actually show up in the data for a given carapace width
fitted_1_filter <- fitted_1 %>%
  left_join(
    data_matrix %>% 
      rownames_to_column("crab_id") %>%
      pivot_longer(cols=2:(dim(data_matrix)[2]+1), names_to="taxon",values_to="reads"),
    by=c("crab_id","taxon")
  ) %>%
  filter(reads!=0)
```

Plot the fitted values
```{r eval=FALSE}
png(here(resultsdir,paste0('zoid_raw_AllTaxa10plus_GroupedByCW_4chains50K.png')), res=300,height=2000,width=3000)
fitted_1_filter %>%
  group_by(taxon,CW_mm) %>%
  summarise(mean_cw=mean, upper_cw=lo,lower_cw=hi, n=length(unique(obs))) %>%
ggplot(aes(y=mean_cw,x=as.numeric(CW_mm))) +
    geom_point() + geom_errorbar(aes(ymin=lower_cw,ymax=upper_cw), width=0.25) + 
  geom_hline(aes(yintercept=0)) +
  geom_text(aes(y=0.001,x=as.numeric(CW_mm),label=n)) +
    facet_wrap(~taxon, scales="free_y") + 
    labs(x="Carapace Width (mm)", y="Bayesian posterior mean", subtitle="Taxa present in 10+ crab") +
    theme_bw() +
    theme(axis.text.x=element_text(angle=45,hjust=1))
dev.off()
```

compare the medians of the fitted values to the median read counts
```{r eval=FALSE}
fitted_readsVest <- fitted_1_filter %>% 
  left_join(data.frame(crab_id=rownames(data_matrix), total_reads=as.numeric(rowSums(data_matrix)))) %>%
  mutate(preads=reads/total_reads) %>%
  group_by(taxon,CW_mm) %>% 
  summarise(mean_preads=mean(preads),sd_preads=sd(preads), n=length(unique(crab_id))) %>%
  mutate(sd_preads=ifelse(is.na(sd_preads),0,sd_preads)) %>%
  left_join(fitted_1_filter %>% dplyr::select(CW_mm,mean,lo,hi,taxon) %>% distinct())

p1 <- ggplot(data=fitted_readsVest, aes(x=CW_mm,y=mean)) +
  geom_point() + geom_errorbar(aes(ymin=lo,ymax=hi), width=0.25) + 
  geom_hline(aes(yintercept=0)) +
  facet_grid(rows=vars(taxon), scales="free_y") +
  xlim(c(5, 20)) +
  theme_bw() + theme(strip.placement = "outside")

p2 <- ggplot(data=fitted_readsVest, aes(x=CW_mm,y=mean_preads)) +
  geom_point() + geom_errorbar(aes(ymin=mean_preads-sd_preads,ymax=mean_preads+sd_preads), width=0.25) + 
  geom_hline(aes(yintercept=0)) +
  facet_grid(rows=vars(taxon)) +
  ylim(c(0,1)) + xlim(c(5, 20)) +
  theme_bw() + theme(strip.placement = "inside")

png(here(resultsdir,'zoid_AllPhyla10plus_4chains50K_fittedVals_v_pReads.png'), res=300,height=4000,width=2000)
plot_grid(p1,p2,ncol=2)
dev.off()
```


Use the smallest crab size *for which the phylum was present* as the reference value (min possible = CW 5mm), and Get the difference between the value at carapace width X and the reference (so that if X > reference, difference is +)
```{r eval=FALSE}
fitted_1_ref <- fitted_1_filter %>%
  # set the reference according to minimum CW in which that phylum was detected
  group_by(phylum) %>% mutate(min_cw=min(CW_mm)) %>% ungroup() %>%
  filter(CW_mm==min_cw) %>%
  dplyr::select(group,phylum,mean,median) %>% rename(ref_mean=mean,ref_median=median) %>%
  right_join(fitted_1_filter,by=c("group","phylum")) %>%
  # calculate change from reference
  mutate(scaled_mean=mean-ref_mean,
         scaled_median=median-ref_median)
```


```{r eval=FALSE}
## plot for each phylum 
png(here(resultsdir,paste0('zoid_AllPhyla10plus_GroupedByCW_4chains50K.png')), res=300,height=2000,width=3000)
ggplot(fitted_1_ref, aes(y=scaled_mean,x=as.numeric(CW_mm))) +
    geom_point() + geom_hline(aes(yintercept=0)) +
    facet_wrap(~phylum, scales="free_y") + 
    labs(x="Carapace Width (mm)", y="Difference from 5mm CW", subtitle=p) +
    theme_bw() +
    theme(axis.text.x=element_text(angle=45,hjust=1))
dev.off()
```



